{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Recognizing Traffic Signs Using Deep Learning\n",
    "### Author: Ashish Panchal (epababl03.ashishp@iima.ac.in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load/Import Libraries\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers import Dropout \n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import regularizers  \n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Flatten, Conv2D, MaxPooling2D \n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load stored data\n",
    "\n",
    "# No. of classes\n",
    "%store -r n_classes\n",
    "\n",
    "# class labels\n",
    "%store -r signs\n",
    "\n",
    "# Training Dataset\n",
    "%store -r X_train\n",
    "%store -r y_train\n",
    "\n",
    "# Test Dataset\n",
    "%store -r X_test\n",
    "%store -r y_test\n",
    "\n",
    "\n",
    "# Validation Dataset\n",
    "%store -r X_valid\n",
    "%store -r y_valid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data Preprocessing \n",
    "\n",
    "### 3.1 Preprocessing Techniques\n",
    "We have applied several preprocessing steps to the input images to achieve the best possible results. we have used the following preprocessing techniques:\n",
    "1. Data Augmentation\n",
    "    - Slight Rotation of Images\n",
    "    - Image Translation\n",
    "2. Shuffling\n",
    "3. Bilateral Filtering\n",
    "    - Grayscaling\n",
    "    - Local Histogram Equalization\n",
    "    - Normalization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we do any data preprocessing, lets have simple dense network to baseline quality of data on basis model accuracy.\n",
    "#### Model Testing without any preprocessing - Establishing Baseline - Neural Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(32*32*3,)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(n_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_11 (Dense)             (None, 128)               393344    \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 43)                5547      \n",
      "=================================================================\n",
      "Total params: 450,475\n",
      "Trainable params: 449,451\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_baseline = X_train.reshape(len(X_train), 32*32*3).astype('float32')\n",
    "X_valid_baseline = X_valid.reshape(len(X_valid), 32*32*3).astype('float32')\n",
    "y_train_baseline = keras.utils.to_categorical(y_train, n_classes)\n",
    "y_valid_baseline = keras.utils.to_categorical(y_valid, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/apanchal/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 34799 samples, validate on 4410 samples\n",
      "Epoch 1/100\n",
      "34799/34799 [==============================] - 9s 250us/step - loss: 2.6912 - accuracy: 0.2776 - val_loss: 2.1739 - val_accuracy: 0.3422\n",
      "Epoch 2/100\n",
      "34799/34799 [==============================] - 6s 166us/step - loss: 1.3719 - accuracy: 0.5757 - val_loss: 1.6383 - val_accuracy: 0.5152\n",
      "Epoch 3/100\n",
      "34799/34799 [==============================] - 6s 175us/step - loss: 0.9747 - accuracy: 0.7006 - val_loss: 1.6049 - val_accuracy: 0.5821\n",
      "Epoch 4/100\n",
      "34799/34799 [==============================] - 6s 173us/step - loss: 0.7517 - accuracy: 0.7685 - val_loss: 1.1461 - val_accuracy: 0.6871\n",
      "Epoch 5/100\n",
      "34799/34799 [==============================] - 6s 174us/step - loss: 0.6658 - accuracy: 0.7969 - val_loss: 1.0965 - val_accuracy: 0.7181\n",
      "Epoch 6/100\n",
      "34799/34799 [==============================] - 6s 174us/step - loss: 0.5892 - accuracy: 0.8214 - val_loss: 1.2484 - val_accuracy: 0.6685\n",
      "Epoch 7/100\n",
      "34799/34799 [==============================] - 7s 193us/step - loss: 0.5335 - accuracy: 0.8392 - val_loss: 0.9312 - val_accuracy: 0.7594\n",
      "Epoch 8/100\n",
      "34799/34799 [==============================] - 9s 267us/step - loss: 0.4932 - accuracy: 0.8531 - val_loss: 0.6522 - val_accuracy: 0.8190\n",
      "Epoch 9/100\n",
      "34799/34799 [==============================] - 12s 352us/step - loss: 0.4389 - accuracy: 0.8682 - val_loss: 0.7937 - val_accuracy: 0.7755\n",
      "Epoch 10/100\n",
      "34799/34799 [==============================] - 16s 457us/step - loss: 0.4147 - accuracy: 0.8743 - val_loss: 0.7079 - val_accuracy: 0.8138\n",
      "Epoch 11/100\n",
      "34799/34799 [==============================] - 15s 444us/step - loss: 0.4023 - accuracy: 0.8786 - val_loss: 0.7234 - val_accuracy: 0.8209\n",
      "Epoch 12/100\n",
      "34799/34799 [==============================] - 12s 333us/step - loss: 0.3737 - accuracy: 0.8866 - val_loss: 0.7487 - val_accuracy: 0.8100\n",
      "Epoch 13/100\n",
      "34799/34799 [==============================] - 10s 277us/step - loss: 0.3673 - accuracy: 0.8907 - val_loss: 0.6400 - val_accuracy: 0.8474\n",
      "Epoch 14/100\n",
      "34799/34799 [==============================] - 13s 368us/step - loss: 0.3267 - accuracy: 0.9020 - val_loss: 0.6634 - val_accuracy: 0.8463\n",
      "Epoch 15/100\n",
      "34799/34799 [==============================] - 10s 281us/step - loss: 0.3426 - accuracy: 0.8956 - val_loss: 0.6084 - val_accuracy: 0.8608\n",
      "Epoch 16/100\n",
      "34799/34799 [==============================] - 8s 228us/step - loss: 0.3300 - accuracy: 0.9021 - val_loss: 0.5928 - val_accuracy: 0.8592\n",
      "Epoch 17/100\n",
      "34799/34799 [==============================] - 8s 232us/step - loss: 0.3229 - accuracy: 0.9022 - val_loss: 0.6669 - val_accuracy: 0.8322\n",
      "Epoch 18/100\n",
      "34799/34799 [==============================] - 8s 239us/step - loss: 0.3040 - accuracy: 0.9088 - val_loss: 0.5531 - val_accuracy: 0.8744\n",
      "Epoch 19/100\n",
      "34799/34799 [==============================] - 8s 235us/step - loss: 0.3038 - accuracy: 0.9082 - val_loss: 0.6520 - val_accuracy: 0.8476\n",
      "Epoch 20/100\n",
      "34799/34799 [==============================] - 8s 237us/step - loss: 0.2940 - accuracy: 0.9120 - val_loss: 0.5634 - val_accuracy: 0.8621\n",
      "Epoch 21/100\n",
      "34799/34799 [==============================] - 8s 238us/step - loss: 0.2773 - accuracy: 0.9176 - val_loss: 0.7535 - val_accuracy: 0.8240\n",
      "Epoch 22/100\n",
      "34799/34799 [==============================] - 9s 253us/step - loss: 0.2731 - accuracy: 0.9189 - val_loss: 0.8814 - val_accuracy: 0.8082\n",
      "Epoch 23/100\n",
      "34799/34799 [==============================] - 9s 271us/step - loss: 0.2563 - accuracy: 0.9235 - val_loss: 0.6362 - val_accuracy: 0.8615\n",
      "Epoch 24/100\n",
      "34799/34799 [==============================] - 10s 279us/step - loss: 0.2680 - accuracy: 0.9189 - val_loss: 0.6007 - val_accuracy: 0.8524\n",
      "Epoch 25/100\n",
      "34799/34799 [==============================] - 9s 269us/step - loss: 0.2520 - accuracy: 0.9244 - val_loss: 0.7201 - val_accuracy: 0.8424\n",
      "Epoch 26/100\n",
      "34799/34799 [==============================] - 9s 244us/step - loss: 0.2369 - accuracy: 0.9284 - val_loss: 0.6453 - val_accuracy: 0.8481\n",
      "Epoch 27/100\n",
      "34799/34799 [==============================] - 8s 223us/step - loss: 0.2419 - accuracy: 0.9266 - val_loss: 0.5313 - val_accuracy: 0.8825\n",
      "Epoch 28/100\n",
      "34799/34799 [==============================] - 8s 226us/step - loss: 0.2316 - accuracy: 0.9292 - val_loss: 0.6363 - val_accuracy: 0.8594\n",
      "Epoch 29/100\n",
      "34799/34799 [==============================] - 7s 197us/step - loss: 0.2342 - accuracy: 0.9301 - val_loss: 0.6292 - val_accuracy: 0.8524\n",
      "Epoch 30/100\n",
      "34799/34799 [==============================] - 7s 207us/step - loss: 0.2288 - accuracy: 0.9308 - val_loss: 0.5927 - val_accuracy: 0.8755\n",
      "Epoch 31/100\n",
      "34799/34799 [==============================] - 7s 207us/step - loss: 0.2113 - accuracy: 0.9365 - val_loss: 0.4933 - val_accuracy: 0.8902\n",
      "Epoch 32/100\n",
      "34799/34799 [==============================] - 7s 206us/step - loss: 0.2208 - accuracy: 0.9330 - val_loss: 0.5379 - val_accuracy: 0.8814\n",
      "Epoch 33/100\n",
      "34799/34799 [==============================] - 7s 208us/step - loss: 0.2187 - accuracy: 0.9330 - val_loss: 0.6331 - val_accuracy: 0.8488\n",
      "Epoch 34/100\n",
      "34799/34799 [==============================] - 7s 215us/step - loss: 0.2122 - accuracy: 0.9373 - val_loss: 0.6160 - val_accuracy: 0.8551\n",
      "Epoch 35/100\n",
      "34799/34799 [==============================] - 8s 234us/step - loss: 0.2017 - accuracy: 0.9382 - val_loss: 0.5479 - val_accuracy: 0.8834\n",
      "Epoch 36/100\n",
      "34799/34799 [==============================] - 8s 242us/step - loss: 0.2099 - accuracy: 0.9365 - val_loss: 0.6307 - val_accuracy: 0.8678\n",
      "Epoch 37/100\n",
      "34799/34799 [==============================] - 9s 246us/step - loss: 0.2013 - accuracy: 0.9393 - val_loss: 0.5058 - val_accuracy: 0.8900\n",
      "Epoch 38/100\n",
      "34799/34799 [==============================] - 8s 242us/step - loss: 0.1951 - accuracy: 0.9397 - val_loss: 0.6751 - val_accuracy: 0.8503\n",
      "Epoch 39/100\n",
      "34799/34799 [==============================] - 8s 244us/step - loss: 0.1891 - accuracy: 0.9433 - val_loss: 0.6130 - val_accuracy: 0.8642\n",
      "Epoch 40/100\n",
      "34799/34799 [==============================] - 9s 250us/step - loss: 0.1893 - accuracy: 0.9422 - val_loss: 0.6574 - val_accuracy: 0.8594\n",
      "Epoch 41/100\n",
      "26240/34799 [=====================>........] - ETA: 1s - loss: 0.1752 - accuracy: 0.9468"
     ]
    }
   ],
   "source": [
    "base_history = model.fit(X_train_baseline, y_train_baseline, batch_size=128, \n",
    "                         epochs=100, verbose=1, validation_data=(X_valid_baseline, y_valid_baseline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
